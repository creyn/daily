Hi there.

**I wrote this email myself, personally**

In the near future we will see a lot of such statements because of all that
AI (Artificial Intelligence) generated content.

AI can generate not only text but also images. And this is a feature that
breaks a lot of KYC software. KYC means Know Your Customer and it is used
by banks and fin-techs to validate clients.

In most cases you have to submit your ID with a **photo**. Then software
checks if this is a valid and legit photo of a person.

And so far this software has had an easy job. Now things get
more complicated as AI can create amazing real life photos for fake IDs.

Next, this can be used to open accounts in different fin-techs as a fake
client. This changes a lot for cryptocurrencies.

At the beginning of cryptocurrencies, about 15 years ago, you could trade
crypto anonymously. Really. Later banks and governments introduced
more thorough KYC and AML (Anti-Money Laundering) laws and regulations. And
now, for almost all crypto trading portals you have to provide a valid ID.

But now those IDs can be faked easily with "real life photos" of fake
people.

Amazing tech and amazing times. And again a cat and a mouse game between
good and evil. Only now, the AI will be fighting each other. Better fasten
your seatbelts.

Only few examples of awesome AI:
- https://lalaland.ai/
- https://this-person-does-not-exist.com/en
- https://www.unrealperson.com/

But there is some AI that checks if a photo is generated by AI:
- https://gan-detector-mayachitra.azurewebsites.net/
-
https://blogs.microsoft.com/on-the-issues/2020/09/01/disinformation-deepfakes-newsguard-video-authenticator/
- https://www.whichfaceisreal.com/

Pawe≈Ç, a human
